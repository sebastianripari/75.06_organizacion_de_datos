{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underfitting & Overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cuando se lleva a cabo el entrenamiento de un algoritmo mediante datos, se pueden producir dos tipos de fenomenos totalmente opuestos, estos son Underfitting y Overfitting. El primero se da cuando el modelo que se genera mediante los datos es demasiado simple y no refleja la variabilidad y complejidad que poseen los datos. En cambio el segundo se da cuando se genera un modelo demasiado complejo que adapta demasiado a los datos pero que luego no logra generalizar la logica de los mismos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"underfitting_overfitting.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias & Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Los conceptos de Bias & Variance ayudan a tratar los temas de Underfitting & Overfitting Podemos asociar el Bias al error que tenemos en el set de entrenamiento.Y la varianza  al error que tenemos en el set de test. Cuando va creciendo la complejidad del modelo el error en el set de entrenamiento (Bias) va disminuyendo pero comienza a crecer el error en el set de test (Variance). La clave es encontrar el punto medio de ambos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"bias_variance.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
