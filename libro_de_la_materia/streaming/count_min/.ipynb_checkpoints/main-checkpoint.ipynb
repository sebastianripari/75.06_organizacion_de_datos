{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count-Min "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de <b>Count-Min Sketch</b> es uno de los algoritmos de streaming mas importante porque permite para cualquier dato de un stream estimar cuantas veces ocurrio el mismo hasta el momento. Esto permite responder todo tipo de problemas siendo uno de los mas frecuentes el denominado <b>Heavy Hitters Problem</b> por lo que empezamos esta seccion con un analisis teorico de este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Heavy Heatters Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema de los <b>Heavy Heatters</b> consiste simplemente en encontrar los <b>elementos mas frecuentes (populares)</b> en un stream. Una forma de plantearlo es dado un stream de <b>n</b> elementos, y un cierto valor <b>k</b>, siendo n un numero muy grande y k un numero relativamente chico encontrar los elementos que ocurren al menos <b>n/k</b> veces en el stream. El caso particular de $k = 2 - \\delta$ con $\\delta$ pequenio consiste en encontrar un elemento que sea mayoria en el stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este problema puede verse tambien de otra forma: encontrar los k elementos mas frecuentes del stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema tiene una enorme cantidad de aplicaciones: los productos mas vendidos de Amazon, los hashtags mas populares de Twitter, las IPs que mas paquetes envian a un router, los queries mas populares de Google, etc. Es facil pensar cientos o miles de cosas interesantes que son variantes en nuestro problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solucion trivial consiste en ordenar todos los elementos del stream O(n log(n)) y luego recorrer linelmente el stream contando la cantidad de veces que aparece cada elemento. Esto, como podemos imaginar, es inaceptable en un stream proque simplemente es imposible tener todos sus elementos en memoria y mucho menos ordenarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lamentablemente no hay forma de resolver el problema de los Heavy Heatters en ninguna de sus variantes en O(n) sin que la complejidad espacial se dispare. Por lo tanto el problema de HH no se puede resolver en O(n) sin almacenar al menos O(n) elementos en memoria. Estas son malas noticias ya que sabemos que no podemos tener el stream almacenado. Es necesario, si queremos resolver este problema en un stream contar con una solucion aproximada ya que hemos visto que la solucion exacta es imposible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El problema de los HH  aproximado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema aproximado tenemos un stream S de n elementos y dado un cierto k queremos cumplir dos condiciones:\n",
    "- Todo valor que ocurre al menos n/k veces en S esta en el resultado.\n",
    "- Todo valor en el resultado ocurre al menos $n/k - \\epsilon n$ en S.\n",
    "- El espacio usado debe ser $O(1/\\epsilon)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que si $\\epsilon$ tiende a 0 en cuyo caso el problema aproximado se vuelve el problema exacto el costo de almacenamiento $1/\\epsilon$ tiende a infinito. Supongamos que usamos $\\epsilon = \\frac{1}{2k}$, el algoritmo aproximado tiene que emitir cualquier valor con frecuencia al menos n/k pero puede tambien emiter valores con frecuencia n/2k el espacio usado por el algoritmo debe ser $1/\\epsilon = 2k$ que es perfectamente viable por ser k un numero manejable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Count-Min Sketch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abordemos ahora el algoritmo que nos interesa: Count-Min. Este algoritmo es bastante simple de explicar, es equivalente a tener <b>l</b> Counting-Filters. Necesitamos entonces <b>l</b> funciones de hashing, llamaremos <b>b</b> al espacio de direcciones de las mismas. Por cada dato del stream, aplicamos las <b>l</b> funciones de hashing e incrementamos el bucket apuntado por las funciones en cada uno de los filtros. La estimacion del algoritmo sobre la cantidad de veces que aparecio un item es minimo de los <b>l</b> contadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por <b>ejemplo</b> supongamos que tenemos los siguientes filtros (<b>l</b>):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4,3,2,6,3,2,1,3] <br>\n",
    "[5,3,4,3,9,4,9,8] <br>\n",
    "[3,6,7,4,9,9,5,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y para un cierto elemento las funciones de hashing nos dan h1 = 3, h2 = 1 y h3 = 0. Nuestra estimacion para la cantidad de veces que ocurrio este elemento es min(6,3,3) = 3. Si el elemento ocurre nuevamente entonces incrementamos los filtros y quedarian:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4,3,2,7,3,2,1,3] <br>\n",
    "[5,4,4,3,9,4,9,8] <br>\n",
    "[4,6,7,4,9,9,5,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el algoritmo es facil resolver el problema de los HH ya que por cada elemento del stream podemos estimar su cardinalidad. El problema de los top-k elementos tambien es sencillo, solo necesitamos una tabla de k elementos y cada vez que ocurre un elemento en el stream estimamos su cardinalidad y actualizamos el ranking segun sea necesario. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitivamente podemos darnos cuenta que Count-Min nunca va a estimar un numero menor que a la cardinalidad real del elemento, pero puede estimar un numero mayor debido a colisiones. En la proxima seccion desarrollaremos la teoria detras del algortimo para estimar el error del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
