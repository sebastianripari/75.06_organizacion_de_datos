{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduccion de Dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La <b>reduccion de dimensiones</b> es una <b>herramienta</b> muy utilizada a la hora de utilizar a algoritmos inteligentes para procesar datos de n dimensiones. En general, a medida que aumenta el tamanio del set de datos (ya sea porque se agregan features o porque se tienen mas muestras) utilizado para entrenar un algoritmo, se requieren mas recuersos para poder procesarlos incluyendo memoria RAM, CPU y espacio en disco para almacenar el set. En determinadas ocasiones tambien puede ocurrir que se agregan mas features a un set de <b>datos que no aportan informacion</b> y en consecuencia no tiene sentido utilizar dichos features para entrenar un algoritmo. Dicho esto, la reduccion de dimensiones se encarga de buscar una representacion mas compacta de un set de datos no solo para optimizar el uso de recursos sino tambien para otro usos: visualizacion de datos, compresion de imagenes, feature engineering, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maldicion de la dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dimension de los datos (es decir, la cantidad de features que tiene un set) tiene un papel muy importante en el rendimiento de un algoritmo. En un caso sencillo, un algoritmo podria aprender sobre datos relacionados al clima teniendo en cuenta varios factores: humedad, temperatura, velocidad del viento, etc. En un caso simple, se podria utilizar un set de datos de una sola dimension que sea la temperatura. Suponiendo que la temperatura fuera un numero entero, se podria pensar que no existen muchos valores posibles para la temperatura. En consecuencia, el algoritmo solo deberia aprender los posibles n valores posibles para la temperatura. Si ahora se agregara una dimension mas (por ejemplo, la humedad) ahora el algoritmo tendria que aprender la informacion en un espacio definido por humedad y temperatura que se vuelve mucho mayor. Suponiendo m valores posibles de humedad, el algoritmo tendria que aprender sobre n * m valores posibles. A medida que se aumentan los features, la dimension va creciendo y se requiere un mayor muestreo para poder entrenar un algoritmo. Algo a destacar es que quitar o agregar features conlleva a que el algoritmo funcione mejor o peor y eso dependera de que algoritmo se utiliza y de los datos en si."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance de un algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El hecho de tener cada vez mas features en un set de datos puede empeorar la performance de un algoritmo. El motivo es trivial. Por ejemplo, si se tiene un set de datos de 1000 puntos en una dimension y se agregar un feature mas enonces el tamanio del set se duplica y en consecuencia se requerira mas RAM y mas CPU para procesar dicha informacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de reduccion de dimensiones sirven muchas veces para reducir el ruido en un set de datos filtrando los features ruidosos y devolvivendo un nuevo set de features con menor cantidad de ruido. En otros casos es posible reducir las dimensiones de nuestro set de datos a unas pocas columnas y luego agregar estas columnas al set de datos original, este aumento de dimensiones muchas veces agrega features en donde la senial es muy fuerte en relacion al ruido y es frecuente que un algoritmo funcione mejor al agregar estos features con respecto a su funcionamiento con el set de datos original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizacion de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La visualizacion es uno de los aspectos mas importantes para poder entender un set de datos. El cerebro humano esta especialmente preparado para entender datos en dos dimensiones y en menor medida en tres dimensiones. Visualizar datos en mas de tres dimensiones es dificil pero existen algunas tecnicas de visualizacion que lo permiten. Por ejemplo un plot de puntos que originalmente tiene dos dimensiones podemos usar el color de los puntos  o le tamanio de los mismos para agregar dos dimensiones mas, esto es especialmente util cuando las dimensiones tienen todas significados diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos para manipular la dimensionalidad de los datos pueden dividirse en dos grandes grupos: <b>metodos lineales</b> y <b>metodos no-lineales</b>. Los metodos lineales por excelencia son <b>SVD</b> y <b>PCA</b> que en realidad son el mismo algoritmo. Los metodos no-lineales son mas variados y se denominan tambien algoritmos para <b>Manifold Learning</b>. El Manifold Learning comprende distintos algoritmos que permiten visualizar datos. Algo interesante de estos algoritmos es que en determinadas ocasiones pueden representar muy bien datos no lineales en dos dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente imagen muestra el resultado de aplicar 8 algoritmos de <b>Manifold Learning</b> diferentes a un mismo set de datos. El set de datos es una superficie con forma de \"S\" en un espacio tridimencional y se puede observar que se trata de un manifold de 2 dimensiones embebido en un espacio de tres dimensiones. Los puntos fueron coloreados de acuerdo a la zona de la \"S\" en la que estan. Un buen algoritmo de Manifold Learning deberia manterner a los puntos que estan cerca en los datos originales como vecinos en su representacion bidimensional. Como puede verse diferentes algoritmos logran esto con diferentes representaciones, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"algoritmos_manifold_learning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
